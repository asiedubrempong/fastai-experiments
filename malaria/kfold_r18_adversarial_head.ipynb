{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Stand Alone Self Attention in Vision Models\n",
    "\n",
    "![Stand Alone SA module](images/sasa.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from sklearn.metrics import auc, roc_curve, precision_recall_curve, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Self Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeSelfAttention(Module):\n",
    "    def __init__(self, d_in, d_out, ks, groups, stride=1):\n",
    "        self.n_c, self.ks, self.groups, self.stride = d_out, ks, groups, stride\n",
    "        # linear transformation for queries, values and keys\n",
    "        self.qx, self.kx, self.vx = [ConvLayer(d_in, d_out, ks=1, norm_type=None,\n",
    "                                               act_cls=None) for _ in range(3)]\n",
    "        # positional embeddings\n",
    "        self.row_embeddings = nn.Parameter(torch.randn(d_out//2, ks))\n",
    "        self.col_embeddings = nn.Parameter(torch.randn(d_out//2, ks))\n",
    "        \n",
    "    def calc_out_shape(self, inp_shape, pad):\n",
    "        out_shape = [(sz + 2*pad - self.ks) // self.stride + 1 for sz in inp_shape]\n",
    "        return out_shape\n",
    "    \n",
    "    def forward(self, x):\n",
    "        query, keys, values = self.qx(x), self.kx(x), self.vx(x)\n",
    "        \n",
    "        pad = (self.ks -1) // 2\n",
    "        \n",
    "        # use unfold to extract the memory blocks and their associated queries\n",
    "        query = F.unfold(query, kernel_size=1, stride=self.stride)\n",
    "        keys = F.unfold(keys, kernel_size=self.ks, padding=pad, stride=self.stride)\n",
    "        values = F.unfold(values, kernel_size=self.ks, padding=pad, stride=self.stride)\n",
    "        \n",
    "        \n",
    "        # reshape and permute the dimensions into the appropriate format for matrix multiplication\n",
    "        query = query.view(query.shape[0], self.groups, self.n_c//self.groups, -1, query.shape[-1]) # bs*G*C//G*1*N\n",
    "        query = query.permute(0, 4, 1, 2, 3) # bs * N * G * C//G * 1\n",
    "        keys = keys.view(keys.shape[0], self.groups, self.n_c//self.groups, -1, keys.shape[-1]) # bs*G*C//G*ks^2*N\n",
    "        keys = keys.permute(0, 4, 1, 2, 3) # bs * N * G * C//G * ks^2\n",
    "        values = values.view(values.shape[0], self.groups, self.n_c//self.groups, -1, values.shape[-1]) # bs*G*C//G*ks^2*N\n",
    "        values = values.permute(0, 4, 1, 2, 3) # bs * N * G * C//G * ks^2\n",
    "        \n",
    "        # get positional embeddings\n",
    "        row_embeddings = self.row_embeddings.unsqueeze(-1).expand(-1, -1, self.ks)\n",
    "        col_embeddings = self.col_embeddings.unsqueeze(-2).expand(-1, self.ks, -1)\n",
    "        \n",
    "        embeddings = torch.cat((row_embeddings, col_embeddings)).view(self.groups,\n",
    "                                self.n_c//self.groups, -1) # G * C//G * ks^2\n",
    "        # add empty dimensions to match the shape of keys\n",
    "        embeddings = embeddings[None, None, -1] # 1 * 1 * G * C//G * ks^2\n",
    "        \n",
    "        # compute attention map\n",
    "        att_map = F.softmax(torch.matmul(query.transpose(-2,-1), keys+embeddings).contiguous(), dim=-1)\n",
    "        # compute final output\n",
    "        out = torch.matmul(att_map, values.transpose(-2,-1)).contiguous().permute(0, 2, 3, 4, 1)\n",
    "        \n",
    "        return out.view(out.shape[0], self.n_c, *self.calc_out_shape(x.shape[-2:], pad)).contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_stem(*sizes):\n",
    "    return [\n",
    "        ConvLayer(sizes[i], sizes[i+1], stride=2 if i==0 else 1)\n",
    "         for i in range(len(sizes) - 1)\n",
    "    ] + [nn.MaxPool2d(kernel_size=3, stride=2, padding=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck(ni, nf, stride):\n",
    "    if stride==1:\n",
    "        layers = [ConvLayer(ni, nf//4, ks=1),\n",
    "              RelativeSelfAttention(nf//4, nf//4, ks=7, groups=8),\n",
    "              ConvLayer(nf//4, nf, ks=1, act_cls=None, norm_type=NormType.BatchZero)]\n",
    "    else:\n",
    "        layers = [ConvLayer(ni, nf//4, ks=1),\n",
    "              RelativeSelfAttention(nf//4, nf//4, ks=7, groups=8),\n",
    "              nn.AvgPool2d(2, ceil_mode=True),\n",
    "              ConvLayer(nf//4, nf, ks=1, act_cls=None, norm_type=NormType.BatchZero)]\n",
    "    \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(Module):\n",
    "    def __init__(self, ni, nf, stride, sa, expansion=1):\n",
    "        self.botl = bottleneck(ni, nf, stride)\n",
    "        self.idconv = noop if ni==nf else ConvLayer(ni, nf, 1, act_cls=None)\n",
    "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.relu(self.botl(x) + self.idconv(self.pool(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Randomization Layer to Protect Against Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandHead(Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        rz_shape = torch.randint(210, 224, (1,))\n",
    "        pad = (224 - rz_shape).item()\n",
    "        h = torch.randint(0, pad+1, (1,))\n",
    "        w = torch.randint(0, pad+1, (1,))\n",
    "        \n",
    "        # step 1 random resize\n",
    "        out = F.interpolate(x, [rz_shape]*2)\n",
    "        # step 2 pad\n",
    "        return F.pad(out, (h, pad-h, w, pad-w))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ResNet module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class xResNet(nn.Sequential):\n",
    "    def __init__(self, channels, n_out, blocks, sa=True, expansion=1):\n",
    "        stem = resnet_stem(channels, 32, 32, 64)\n",
    "        self.group_sizes = [64, 64, 128, 256, 512]\n",
    "        for i in range(1, len(self.group_sizes)): \n",
    "            self.group_sizes[i] *= expansion\n",
    "        groups = [self._make_group(idx, n_blocks, sa=sa if idx==0 else False) \n",
    "                      for idx, n_blocks in enumerate(blocks)]\n",
    "        \n",
    "        super().__init__(RandHead(), *stem, *groups,\n",
    "                         nn.AdaptiveAvgPool2d(1), Flatten(),\n",
    "                         nn.Linear(self.group_sizes[-1], n_out))\n",
    "        \n",
    "    def _make_group(self, idx, n_blocks, sa):\n",
    "        stride = 1 if idx==1 else 2\n",
    "        ni, nf = self.group_sizes[idx], self.group_sizes[idx+1]\n",
    "        return nn.Sequential(*[\n",
    "            ResNetBlock(ni if i==0 else nf, nf, stride=stride if i==0 else 1,\n",
    "                        sa=sa if i==n_blocks-1 else False)\n",
    "             for i in range(n_blocks)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('.ipynb_checkpoints'),Path('cell_images')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('data/')\n",
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = get_image_files(path/'cell_images/cell_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(o):\n",
    "    return [o.parent.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "lbls = []\n",
    "\n",
    "for img in imgs:\n",
    "    idxs.append(img.name)\n",
    "    lbls.append(get_y(img)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(size, bs, valid_idx):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
    "       get_items=get_image_files,\n",
    "       splitter=IndexSplitter(valid_idx),\n",
    "       get_y=get_y,\n",
    "       item_tfms=Resize(size),\n",
    "       batch_tfms=[*aug_transforms(flip_vert=True, max_zoom=1.2, max_warp=0), Normalize()])\n",
    "    \n",
    "    return dblock.dataloaders(path/'cell_images/cell_images', bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "y_true = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.531832</td>\n",
       "      <td>0.464954</td>\n",
       "      <td>0.840893</td>\n",
       "      <td>02:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.206593</td>\n",
       "      <td>0.169722</td>\n",
       "      <td>0.952286</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.182522</td>\n",
       "      <td>0.158924</td>\n",
       "      <td>0.947388</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.180504</td>\n",
       "      <td>0.133254</td>\n",
       "      <td>0.955733</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.163738</td>\n",
       "      <td>0.130562</td>\n",
       "      <td>0.953284</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.168682</td>\n",
       "      <td>0.170936</td>\n",
       "      <td>0.950835</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.143835</td>\n",
       "      <td>0.136048</td>\n",
       "      <td>0.957910</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.150238</td>\n",
       "      <td>0.141189</td>\n",
       "      <td>0.949020</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.142057</td>\n",
       "      <td>0.126447</td>\n",
       "      <td>0.952014</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.140169</td>\n",
       "      <td>0.116269</td>\n",
       "      <td>0.960268</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.132639</td>\n",
       "      <td>0.107640</td>\n",
       "      <td>0.962627</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.124955</td>\n",
       "      <td>0.107285</td>\n",
       "      <td>0.964078</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.128288</td>\n",
       "      <td>0.101570</td>\n",
       "      <td>0.966437</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.129834</td>\n",
       "      <td>0.097925</td>\n",
       "      <td>0.967344</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.119868</td>\n",
       "      <td>0.099279</td>\n",
       "      <td>0.966437</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.120082</td>\n",
       "      <td>0.094088</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.119139</td>\n",
       "      <td>0.092215</td>\n",
       "      <td>0.971426</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.109958</td>\n",
       "      <td>0.094080</td>\n",
       "      <td>0.968070</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.104481</td>\n",
       "      <td>0.093714</td>\n",
       "      <td>0.970337</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.113548</td>\n",
       "      <td>0.092479</td>\n",
       "      <td>0.968705</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.563511</td>\n",
       "      <td>0.512608</td>\n",
       "      <td>0.775943</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.202331</td>\n",
       "      <td>0.140095</td>\n",
       "      <td>0.953465</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187205</td>\n",
       "      <td>0.132805</td>\n",
       "      <td>0.955098</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.180078</td>\n",
       "      <td>0.135368</td>\n",
       "      <td>0.956096</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.176826</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.958364</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.163576</td>\n",
       "      <td>0.129507</td>\n",
       "      <td>0.959543</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.163538</td>\n",
       "      <td>0.118817</td>\n",
       "      <td>0.956731</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.156214</td>\n",
       "      <td>0.121968</td>\n",
       "      <td>0.955189</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.146010</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>0.960994</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.133884</td>\n",
       "      <td>0.108878</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.135679</td>\n",
       "      <td>0.136073</td>\n",
       "      <td>0.955279</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.128487</td>\n",
       "      <td>0.103443</td>\n",
       "      <td>0.962718</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.128090</td>\n",
       "      <td>0.094942</td>\n",
       "      <td>0.966437</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.118462</td>\n",
       "      <td>0.096373</td>\n",
       "      <td>0.966255</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.115254</td>\n",
       "      <td>0.095501</td>\n",
       "      <td>0.967798</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.118777</td>\n",
       "      <td>0.091270</td>\n",
       "      <td>0.969702</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.116176</td>\n",
       "      <td>0.090183</td>\n",
       "      <td>0.968886</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.117635</td>\n",
       "      <td>0.088803</td>\n",
       "      <td>0.969430</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.113555</td>\n",
       "      <td>0.089363</td>\n",
       "      <td>0.968251</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.104608</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.969340</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.502862</td>\n",
       "      <td>0.419112</td>\n",
       "      <td>0.866020</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.196545</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>0.952921</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.175569</td>\n",
       "      <td>0.143203</td>\n",
       "      <td>0.953647</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.162562</td>\n",
       "      <td>0.139553</td>\n",
       "      <td>0.957366</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.175195</td>\n",
       "      <td>0.133350</td>\n",
       "      <td>0.957003</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153793</td>\n",
       "      <td>0.135653</td>\n",
       "      <td>0.956005</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.149410</td>\n",
       "      <td>0.123980</td>\n",
       "      <td>0.958545</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.143443</td>\n",
       "      <td>0.110695</td>\n",
       "      <td>0.962718</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.141468</td>\n",
       "      <td>0.142956</td>\n",
       "      <td>0.950653</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.144461</td>\n",
       "      <td>0.103184</td>\n",
       "      <td>0.965348</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.138466</td>\n",
       "      <td>0.101633</td>\n",
       "      <td>0.965893</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.129878</td>\n",
       "      <td>0.096429</td>\n",
       "      <td>0.967163</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.127792</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.961266</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.116703</td>\n",
       "      <td>0.098640</td>\n",
       "      <td>0.966165</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.130422</td>\n",
       "      <td>0.098443</td>\n",
       "      <td>0.966255</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.126874</td>\n",
       "      <td>0.093042</td>\n",
       "      <td>0.968342</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.115892</td>\n",
       "      <td>0.088687</td>\n",
       "      <td>0.968523</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.112015</td>\n",
       "      <td>0.089327</td>\n",
       "      <td>0.968523</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.117331</td>\n",
       "      <td>0.091553</td>\n",
       "      <td>0.969702</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.109461</td>\n",
       "      <td>0.088433</td>\n",
       "      <td>0.969068</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>0.441438</td>\n",
       "      <td>0.840773</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.196394</td>\n",
       "      <td>0.152362</td>\n",
       "      <td>0.947559</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.186037</td>\n",
       "      <td>0.190033</td>\n",
       "      <td>0.936763</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172928</td>\n",
       "      <td>0.148783</td>\n",
       "      <td>0.950372</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.164753</td>\n",
       "      <td>0.157867</td>\n",
       "      <td>0.944656</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.142089</td>\n",
       "      <td>0.136086</td>\n",
       "      <td>0.954727</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.151851</td>\n",
       "      <td>0.126226</td>\n",
       "      <td>0.955362</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.156823</td>\n",
       "      <td>0.132097</td>\n",
       "      <td>0.956904</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.128396</td>\n",
       "      <td>0.116626</td>\n",
       "      <td>0.957721</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.142917</td>\n",
       "      <td>0.145687</td>\n",
       "      <td>0.949465</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.141173</td>\n",
       "      <td>0.113655</td>\n",
       "      <td>0.956541</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.128255</td>\n",
       "      <td>0.113258</td>\n",
       "      <td>0.959263</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.131105</td>\n",
       "      <td>0.106878</td>\n",
       "      <td>0.962802</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.125346</td>\n",
       "      <td>0.104381</td>\n",
       "      <td>0.961713</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.123063</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.962348</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.111889</td>\n",
       "      <td>0.100958</td>\n",
       "      <td>0.963074</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.106492</td>\n",
       "      <td>0.101073</td>\n",
       "      <td>0.962802</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.105226</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.962348</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>0.097394</td>\n",
       "      <td>0.964072</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.113176</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>0.962439</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_multi</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.503224</td>\n",
       "      <td>0.435323</td>\n",
       "      <td>0.849664</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.209914</td>\n",
       "      <td>0.166850</td>\n",
       "      <td>0.945836</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187666</td>\n",
       "      <td>0.154499</td>\n",
       "      <td>0.946199</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172909</td>\n",
       "      <td>0.141712</td>\n",
       "      <td>0.950553</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.166059</td>\n",
       "      <td>0.155283</td>\n",
       "      <td>0.947197</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159721</td>\n",
       "      <td>0.126397</td>\n",
       "      <td>0.956451</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.150200</td>\n",
       "      <td>0.122845</td>\n",
       "      <td>0.956451</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.162586</td>\n",
       "      <td>0.117667</td>\n",
       "      <td>0.958900</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.148136</td>\n",
       "      <td>0.115064</td>\n",
       "      <td>0.961531</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.136763</td>\n",
       "      <td>0.115524</td>\n",
       "      <td>0.961894</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.134108</td>\n",
       "      <td>0.114029</td>\n",
       "      <td>0.962983</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.129115</td>\n",
       "      <td>0.106945</td>\n",
       "      <td>0.961350</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.120570</td>\n",
       "      <td>0.101271</td>\n",
       "      <td>0.963800</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.119676</td>\n",
       "      <td>0.103288</td>\n",
       "      <td>0.962892</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.119015</td>\n",
       "      <td>0.098638</td>\n",
       "      <td>0.965070</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.116890</td>\n",
       "      <td>0.094418</td>\n",
       "      <td>0.965977</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.114957</td>\n",
       "      <td>0.096886</td>\n",
       "      <td>0.965796</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.117996</td>\n",
       "      <td>0.094747</td>\n",
       "      <td>0.963890</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.107755</td>\n",
       "      <td>0.094367</td>\n",
       "      <td>0.965614</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.103361</td>\n",
       "      <td>0.095320</td>\n",
       "      <td>0.966431</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for _, valid_idx in skf.split(idxs, lbls):\n",
    "    dls = get_dls(200, 64, valid_idx)\n",
    "    model = xResNet(3, dls.c, [2,2,2,2])\n",
    "    learn= Learner(dls, model, metrics=partial(accuracy_multi, thresh=0.5))\n",
    "    \n",
    "    learn.fit_one_cycle(20, 1e-3)\n",
    "    \n",
    "    probs, y = learn.get_preds()\n",
    "    preds.append(probs)\n",
    "    y_true.append(y)\n",
    "    \n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(200, 64, valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('record.pkl', 'wb') as f:\n",
    "    pickle.dump([preds, y_true], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metrics for each fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5512,), (5512,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = np.argmax(preds[0].numpy(), axis=-1)\n",
    "y = np.argmax(y_true[0].numpy(), axis=-1)\n",
    "y.shape, ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Parasitized       0.98      0.96      0.97      2756\n",
      "  Uninfected       0.96      0.98      0.97      2756\n",
      "\n",
      "    accuracy                           0.97      5512\n",
      "   macro avg       0.97      0.97      0.97      5512\n",
      "weighted avg       0.97      0.97      0.97      5512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = list(dls.vocab)\n",
    "report = classification_report(y, ps, target_names=classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5512,), (5512,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = np.argmax(preds[1].numpy(), axis=-1)\n",
    "y = np.argmax(y_true[1].numpy(), axis=-1)\n",
    "y.shape, ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Parasitized       0.98      0.96      0.97      2756\n",
      "  Uninfected       0.96      0.98      0.97      2756\n",
      "\n",
      "    accuracy                           0.97      5512\n",
      "   macro avg       0.97      0.97      0.97      5512\n",
      "weighted avg       0.97      0.97      0.97      5512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = list(dls.vocab)\n",
    "report = classification_report(y, ps, target_names=classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5512,), (5512,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = np.argmax(preds[2].numpy(), axis=-1)\n",
    "y = np.argmax(y_true[2].numpy(), axis=-1)\n",
    "y.shape, ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Parasitized       0.98      0.95      0.97      2756\n",
      "  Uninfected       0.95      0.98      0.97      2756\n",
      "\n",
      "    accuracy                           0.97      5512\n",
      "   macro avg       0.97      0.97      0.97      5512\n",
      "weighted avg       0.97      0.97      0.97      5512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = list(dls.vocab)\n",
    "report = classification_report(y, ps, target_names=classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5511,), (5511,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = np.argmax(preds[3].numpy(), axis=-1)\n",
    "y = np.argmax(y_true[3].numpy(), axis=-1)\n",
    "y.shape, ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Parasitized       0.98      0.95      0.96      2755\n",
      "  Uninfected       0.95      0.98      0.96      2756\n",
      "\n",
      "    accuracy                           0.96      5511\n",
      "   macro avg       0.96      0.96      0.96      5511\n",
      "weighted avg       0.96      0.96      0.96      5511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = list(dls.vocab)\n",
    "report = classification_report(y, ps, target_names=classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5511,), (5511,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = np.argmax(preds[4].numpy(), axis=-1)\n",
    "y = np.argmax(y_true[4].numpy(), axis=-1)\n",
    "y.shape, ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Parasitized       0.98      0.96      0.97      2756\n",
      "  Uninfected       0.96      0.98      0.97      2755\n",
      "\n",
      "    accuracy                           0.97      5511\n",
      "   macro avg       0.97      0.97      0.97      5511\n",
      "weighted avg       0.97      0.97      0.97      5511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = list(dls.vocab)\n",
    "report = classification_report(y, ps, target_names=classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
