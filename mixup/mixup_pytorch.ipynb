{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *mixup*: BEYOND EMPIRICAL RISK MINIMIZATION\n",
    "---\n",
    "PyTorch implementation, Uses Fastai for loading and processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the fastai library also imports the neccessary PyTorch modules\n",
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/jupyter/.fastai/data/mnist_png/training'),Path('/home/jupyter/.fastai/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('training'),Path('testing')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(blocks=(ImageBlock(cls=PILImageBW), CategoryBlock),\n",
    "                   get_items=get_image_files,\n",
    "                   get_y=parent_label,\n",
    "                   splitter=RandomSplitter(seed=42),\n",
    "                   batch_tfms=Normalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(path/'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = dls.train.one_batch()\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check to see if mean is 0 and standard deviation is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImageBW([-0.0038], device='cuda:0'),\n",
       " TensorImageBW([0.9965], device='cuda:0'))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.mean([0, 2, 3]), xb.std([0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(nrows=1, ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(0.4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training loop which will implement *mixup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dls, loss_func, optimizer, epochs, alpha):\n",
    "    # beta distribution to sample values of lambda\n",
    "    dist = torch.distributions.beta.Beta(torch.tensor([alpha]), \n",
    "                                         torch.tensor([alpha]))\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        r_train_losses = []\n",
    "        r_val_losses = []\n",
    "        r_accs = []\n",
    "        # training phase\n",
    "        for xb, yb in dls.train:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # for mixup, we have to randomly shuffle each batch\n",
    "            idx = torch.randperm(xb.shape[0])\n",
    "            xb_new = xb[idx]\n",
    "            yb_new = yb[idx]\n",
    "            # sample weights for each image in the batch from a beta distribution\n",
    "            lamda = dist.sample([xb.shape[0]]).cuda()\n",
    "            lamda = torch.max(lamda, 1-lamda) # remove duplicates\n",
    "            # add empty dimensions to match size of mini batch\n",
    "            lamda = lamda[:, None, None]\n",
    "            mixed_up_xb = lamda * xb + (1-lamda) * xb_new\n",
    "            \n",
    "            # forward pass \n",
    "            logits = model(mixed_up_xb)\n",
    "            # to avoiid using one hot labels, we perform the weighting of\n",
    "            # the labels on the loss instead\n",
    "            loss = lamda * loss_func(logits, yb) + (1-lamda) * loss_func(logits, yb_new)\n",
    "            loss = loss.mean()\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            r_train_losses.append(loss/xb.shape[0])\n",
    "            \n",
    "        # validation phase\n",
    "        for xb, yb in dls.valid:\n",
    "            with torch.no_grad():\n",
    "                model.eval() # put the model in eval mode\n",
    "                \n",
    "                logits = model(xb)\n",
    "                loss = loss_func(logits, yb)\n",
    "                loss = loss.mean()\n",
    "                r_val_losses.append(loss/xb.shape[0]) # add to running_losses\n",
    "                \n",
    "                acc = accuracy(logits, yb) # calculate accuracy\n",
    "                r_accs.append(acc)\n",
    "                \n",
    "        model.train() # put model back in training mode()\n",
    "        \n",
    "        print(f'Epoch: {i}/{epochs}, Train loss: {tensor(r_train_losses).mean():.4f}'\\\n",
    "              f'Val loss: {tensor(r_val_losses).mean():.4f} Val acc: {tensor(r_accs).mean():.4f}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, targs):\n",
    "    preds = preds.softmax(dim=1)\n",
    "    return (preds.argmax(dim=-1) == targs).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/20, Train loss: 0.0138Val loss: 0.0035 Val acc: 0.9811\n",
      "Epoch: 1/20, Train loss: 0.0130Val loss: 0.0029 Val acc: 0.9830\n",
      "Epoch: 2/20, Train loss: 0.0125Val loss: 0.0029 Val acc: 0.9834\n",
      "Epoch: 3/20, Train loss: 0.0123Val loss: 0.0028 Val acc: 0.9845\n",
      "Epoch: 4/20, Train loss: 0.0120Val loss: 0.0026 Val acc: 0.9851\n",
      "Epoch: 5/20, Train loss: 0.0118Val loss: 0.0028 Val acc: 0.9855\n",
      "Epoch: 6/20, Train loss: 0.0116Val loss: 0.0031 Val acc: 0.9860\n",
      "Epoch: 7/20, Train loss: 0.0115Val loss: 0.0031 Val acc: 0.9867\n",
      "Epoch: 8/20, Train loss: 0.0114Val loss: 0.0028 Val acc: 0.9844\n",
      "Epoch: 9/20, Train loss: 0.0113Val loss: 0.0024 Val acc: 0.9855\n",
      "Epoch: 10/20, Train loss: 0.0112Val loss: 0.0025 Val acc: 0.9865\n",
      "Epoch: 11/20, Train loss: 0.0111Val loss: 0.0022 Val acc: 0.9869\n",
      "Epoch: 12/20, Train loss: 0.0110Val loss: 0.0025 Val acc: 0.9867\n",
      "Epoch: 13/20, Train loss: 0.0111Val loss: 0.0028 Val acc: 0.9862\n",
      "Epoch: 14/20, Train loss: 0.0109Val loss: 0.0024 Val acc: 0.9875\n",
      "Epoch: 15/20, Train loss: 0.0110Val loss: 0.0026 Val acc: 0.9865\n",
      "Epoch: 16/20, Train loss: 0.0109Val loss: 0.0024 Val acc: 0.9847\n",
      "Epoch: 17/20, Train loss: 0.0108Val loss: 0.0023 Val acc: 0.9886\n",
      "Epoch: 18/20, Train loss: 0.0109Val loss: 0.0026 Val acc: 0.9872\n",
      "Epoch: 19/20, Train loss: 0.0108Val loss: 0.0029 Val acc: 0.9865\n"
     ]
    }
   ],
   "source": [
    "train(model, dls, loss_func, optimizer, 20, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
