{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a CNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = torch.randn((5, 3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn((32, 3, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unf = nn.Unfold((3,3), padding=0, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27, 961])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_unf = unf(im)\n",
    "im_unf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 961, 27])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_unf.transpose_(1,2)\n",
    "im_unf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.view(weights.shape[0], -1).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 961, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve = im_unf @ weights.view(weights.shape[0], -1).T\n",
    "convolve.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = nn.Fold((31, 31), (1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 32, 31, 31])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = fold(convolve.transpose(1,2))\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**check how bias works and add bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels = in_channels, out_channels\n",
    "        self.kernel_size = self._pair(kernel_size)\n",
    "        self.stride, self.padding = stride, padding\n",
    "        \n",
    "        # fan in for weight initialization\n",
    "        fan_in = torch.tensor(in_channels * self.kernel_size[0] * self.kernel_size[1], dtype=float)\n",
    "        # use kaiming initialization\n",
    "        self.weight = nn.Parameter(torch.randn((out_channels, in_channels, *self.kernel_size)) / torch.sqrt(2/fan_in))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert(x.shape[1] == self.in_channels)\n",
    "        unf = F.unfold(x, self.kernel_size, padding=self.padding, stride=self.stride)\n",
    "        # reshape\n",
    "        unf.transpose_(1, 2)\n",
    "        # convolve image with the filters\n",
    "        conv = (unf @ self.weight.view(self.weight.shape[0], -1).T).transpose(1, 2)\n",
    "        # fold back to appropriate size\n",
    "        oz = self.output_size(x.shape[2], x.shape[3])\n",
    "        return F.fold(conv, oz, (1,1))\n",
    "        \n",
    "    def output_size(self, x_r, x_c):\n",
    "        oz_r = self.cal_output_dim(x_r, self.kernel_size[0])\n",
    "        # check if the image and filters are square\n",
    "        if x_r == x_c and self.kernel_size[0] == self.kernel_size[1]:\n",
    "            return oz_r, oz_r\n",
    "        oz_c = self.cal_output_dim(x_c, self.kernel_size[1])\n",
    "        return oz_r, oz_c\n",
    "    \n",
    "    def cal_output_dim(self, n, kernel_size):\n",
    "        return (n + 2 * self.padding - kernel_size) // self.stride + 1\n",
    "        \n",
    "    def _pair(self, k):\n",
    "        # utility function to allow the use of a single integer for the kernel size\n",
    "        if isinstance(k, Iterable):\n",
    "            return k\n",
    "        return tuple((k, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_conv1 = MyConv2d(3, 16, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = torch.randn((1, 3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = my_conv1(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 26, 26])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = DataBlock(\n",
    "            blocks=(ImageBlock(cls=PILImageBW), CategoryBlock),\n",
    "            get_items=get_image_files,\n",
    "            splitter=Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            MyConv2d(1, 4, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            MyConv2d(4, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            MyConv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            MyConv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stop using nn.Parameter and implement backprop from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `cnn_learner` not found.\n"
     ]
    }
   ],
   "source": [
    "cnn_learner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision import cnn_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
